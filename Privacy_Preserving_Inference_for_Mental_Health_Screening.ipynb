{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **üß† Privacy-Preserving Mental Health Risk Detection**\n",
        "\n",
        "This demo project demonstrates a lightweight privacy-preserving AI system for detecting early mental health risk from short text messages using encrypted inference. We simulate a realistic healthcare scenario where patient-generated data must remain confidential‚Äîyet still usable for AI-powered triage. By combining sentence embeddings, classical machine learning, and Fully Homomorphic Encryption (FHE), we enable secure inference on encrypted inputs without revealing sensitive text.\n",
        "\n",
        "**üîê Key Features**\n",
        "\n",
        "**Federated Learning Scenario**: Model is trained locally; inference is performed securely on encrypted user inputs‚Äîideal for settings with distributed, sensitive healthcare data.\n",
        "\n",
        "\n",
        "**Privacy-Preserving AI**: Raw user data never leaves the client side unencrypted‚Äîcomputation and risk scoring occur securely in ciphertext space.\n",
        "\n",
        "**Sentence Embeddings**: Uses all-MiniLM-L6-v2 to convert input text into dense semantic vectors.\n",
        "\n",
        "**Encrypted Inference with TenSEAL**: Applies the CKKS scheme to run logistic regression on encrypted embeddings.\n"
      ],
      "metadata": {
        "id": "XfrKkjpn-FLB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d3RH_mti6zR"
      },
      "source": [
        "!pip install sentence-transformers tenseal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üßÆ Introduction to CKKS and TenSEAL**\n",
        "\n",
        "To enable privacy-preserving inference over sensitive clinical text, this project leverages the CKKS (Cheon-Kim-Kim-Song) scheme for approximate homomorphic encryption. Unlike traditional encryption, CKKS supports arithmetic directly on encrypted real numbers, making it ideal for machine learning workflows involving floating-point operations like dot products and linear models.\n",
        "\n",
        "We use [TenSEAL](https://github.com/OpenMined/TenSEAL) ‚Äî a Python library built on top of Microsoft SEAL ‚Äî to:\n",
        "\n",
        "\n",
        "\n",
        "*   Encrypt high-dimensional sentence embeddings (e.g., from MiniLM)\n",
        "*   Perform encrypted linear inference (e.g., logistic regression)\n",
        "*   Decrypt only the final result, preserving end-to-end confidentiality\n",
        "*   By operating entirely on ciphertexts, TenSEAL allows computations to be outsourced to untrusted environments (e.g., cloud or remote nodes) without revealing inputs, model parameters, or intermediate results.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7kTzMoeVNh_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1. Simulate 400 labeled text messages\n",
        "mental_health_texts = [\n",
        "    \"I feel hopeless and tired all the time.\",\n",
        "    \"Lately, I can't concentrate and everything feels overwhelming.\",\n",
        "    \"I barely talk to anyone and feel isolated.\",\n",
        "    \"School is stressing me out beyond what I can handle.\",\n",
        "    \"I have no energy to do anything, even things I used to enjoy.\",\n",
        "    \"I feel anxious constantly, even when nothing is wrong.\",\n",
        "    \"I'm not sleeping well and my appetite is gone.\",\n",
        "    \"Everything feels meaningless and I just want to be left alone.\",\n",
        "    \"I cry randomly and can't explain why.\",\n",
        "    \"Even getting out of bed feels like a chore.\"\n",
        "] * 20  # 200 samples\n",
        "\n",
        "no_problem_texts = [\n",
        "    \"I‚Äôve been sleeping well and enjoying my time with friends.\",\n",
        "    \"I feel confident and motivated about my goals.\",\n",
        "    \"I‚Äôve been going for daily walks and eating healthy.\",\n",
        "    \"Things at school are busy but manageable.\",\n",
        "    \"I enjoy socializing and staying active.\",\n",
        "    \"Life has been stable and I‚Äôm feeling grateful.\",\n",
        "    \"I‚Äôve been productive and focused lately.\",\n",
        "    \"My energy levels are good and I feel optimistic.\",\n",
        "    \"I‚Äôve been taking care of myself and feeling balanced.\",\n",
        "    \"Everything is going smoothly and I‚Äôm content.\"\n",
        "] * 20  # 200 samples\n",
        "\n",
        "texts = mental_health_texts + no_problem_texts\n",
        "labels = [1]*200 + [0]*200\n",
        "\n",
        "df = pd.DataFrame({'text': texts, 'mental_health_problem': labels})\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 2. Encode messages into embeddings\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_embeddings = encoder.encode(df['text'].tolist())\n",
        "y = df['mental_health_problem'].values\n",
        "\n",
        "# 3. Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHJnC7UEAQLg",
        "outputId": "1e5e7c14-16af-4695-e1f9-768aea435245"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "utpYvHZJYXUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîì Plaintext Inference Version**\n",
        "\n",
        "This simplified version demonstrates the same mental health risk detection pipeline without encryption, serving as a baseline for comparison.\n",
        "\n",
        "*   Text messages are embedded using a pretrained MiniLM model.\n",
        "*   A logistic regression classifier predicts mental health risk based on those embeddings.\n",
        "*   Inference is performed directly on plaintext vectors using a standard dot product.\n",
        "*   Useful for validating model performance before deploying privacy-preserving encrypted inference.\n"
      ],
      "metadata": {
        "id": "1pfpOBwHBSRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Predict on new input (plaintext inference)\n",
        "test_text = \"I feel hopeless and tired all the time.\"\n",
        "embedding = encoder.encode([test_text])[0]\n",
        "score = np.dot(model.coef_[0], embedding) + model.intercept_[0]\n",
        "probability = 1 / (1 + np.exp(-score))\n",
        "\n",
        "print(f\"\\nPrediction probability for:\\n\\\"{test_text}\\\"\\n‚Üí {probability:.4f}\")\n",
        "print(\"‚úÖ Risk Detected\" if probability > 0.5 else \"‚úÖ No Risk Detected\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb3De6iVCKOO",
        "outputId": "46df19be-3a79-4b69-a089-91e3e71de1b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction probability for:\n",
            "\"I feel hopeless and tired all the time.\"\n",
            "‚Üí 0.9036\n",
            "‚úÖ Risk Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bsUcAQ63YZ18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîê Why Encryption Matters in Clinical AI: Protecting Against Embedding Leakage**\n",
        "\n",
        "\n",
        "\n",
        "*   üîì Note: In clinical environments, using plaintext or even unencrypted embeddings is generally not permitted, as embeddings‚Äîthough not directly human-readable‚Äîcan still be vulnerable to inversion or re-identification attacks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J3juGu1MIGMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load encoder and corpus of possible texts\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "corpus_sentences = [\n",
        "    \"I feel tired and sad all the time.\",\n",
        "    \"I'm excited about my new project.\",\n",
        "    \"Everything feels meaningless.\",\n",
        "    \"I can't concentrate on anything lately.\",\n",
        "    \"I‚Äôve been sleeping well and eating healthy.\",\n",
        "    \"Life is overwhelming and I want to cry.\",\n",
        "    \"My motivation is gone and I feel hopeless.\"\n",
        "]\n",
        "\n",
        "# 2. Encode known corpus of candidate sentences\n",
        "corpus_embeddings = encoder.encode(corpus_sentences)\n",
        "\n",
        "# 3. Simulate intercepted embedding (e.g., from a client query)\n",
        "simulated_embedding = embedding = encoder.encode([test_text])[0]  # This is what gets intercepted\n",
        "\n",
        "# 4. Attacker attempts reconstruction via cosine similarity\n",
        "similarities = cosine_similarity([simulated_embedding], corpus_embeddings)\n",
        "closest_idx = np.argmax(similarities)\n",
        "\n",
        "# 5. Display result\n",
        "print(f\"‚ùó Intercepted embedding likely corresponds to:\")\n",
        "print(f\"üîç Closest match: \\\"{corpus_sentences[closest_idx]}\\\"\")\n",
        "print(f\"üìà Similarity score: {similarities[0][closest_idx]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT5fPcJ8Hkbl",
        "outputId": "11a1ffed-b370-4e58-e47b-d821f95ddc11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùó Intercepted embedding likely corresponds to:\n",
            "üîç Closest match: \"I feel tired and sad all the time.\"\n",
            "üìà Similarity score: 0.7972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qcOqMHqGYbPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**üîê Encrypted Inference with CKKS (TenSEAL)**\n",
        "\n",
        "This version demonstrates inference over encrypted input using the CKKS homomorphic encryption scheme via the TenSEAL library.\n",
        "\n",
        "\n",
        "*   This setup mimics a privacy-preserving inference service where sensitive user input remains encrypted throughout the prediction process‚Äîideal for federated healthcare settings or scenarios involving untrusted compute infrastructure.\n",
        "*   The input embedding (from MiniLM) is encrypted using CKKS before being sent to the model.\n",
        "*   The logistic regression model performs a dot product and adds bias entirely in ciphertext space.\n",
        "*   The encrypted result is decrypted only after computation, and the sigmoid function is applied client-side to produce a probability score.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0OljuveKColy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tenseal as ts\n",
        "\n",
        "# 5. Setup TenSEAL encryption context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        ")\n",
        "context.global_scale = 2 ** 40\n",
        "context.generate_galois_keys()\n",
        "\n",
        "# 6. Encrypted inference\n",
        "test_text = \"I feel hopeless and tired all the time.\"\n",
        "#test_text = \"I am good.\"\n",
        "embedding = encoder.encode([test_text])[0]\n",
        "\n",
        "encrypted_vec = ts.ckks_vector(context, embedding.tolist())\n",
        "\n",
        "weights = model.coef_[0]\n",
        "bias = model.intercept_[0]\n",
        "\n",
        "# Compute encrypted dot product + bias\n",
        "encrypted_result = encrypted_vec.dot(weights) + bias\n",
        "\n",
        "# Decrypt and apply sigmoid\n",
        "score = encrypted_result.decrypt()[0]\n",
        "probability = 1 / (1 + np.exp(-score))\n",
        "\n",
        "print(f\"\\nEncrypted prediction probability for:\\n\\\"{test_text}\\\"\\n‚Üí {probability:.4f}\")\n",
        "print(\"‚úÖ Risk Detected\" if probability > 0.5 else \"‚úÖ No Risk Detected\")"
      ],
      "metadata": {
        "id": "-MJLokpVYrh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4a588d-daac-4136-df26-c39914700715"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encrypted prediction probability for:\n",
            "\"I feel hopeless and tired all the time.\"\n",
            "‚Üí 0.9036\n",
            "‚úÖ Risk Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "miWUOcrSYcqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üõ°Ô∏è Simulated Attacker Scenario: Why Homomorphic Encryption Prevents Data Leakage**\n",
        "\n",
        "This section demonstrates how a malicious actor ‚Äî even if they intercept the encrypted embedding or encrypted inference result ‚Äî cannot extract any meaningful information.\n",
        "\n",
        "Three common attack attempts are shown:\n",
        "\n",
        "**üîì Direct Inspection of Encrypted Vector**\n",
        "\n",
        "The attacker tries to read or print the contents of the encrypted vector.\n",
        "‚Üí Fails: CKKS ciphertexts are opaque; raw values are hidden.\n",
        "\n",
        "**üîç Cosine Similarity Matching**\n",
        "\n",
        "The attacker tries to compare the encrypted vector with known plaintext embeddings (e.g. via cosine similarity) to infer meaning.\n",
        "‚Üí Fails: Encrypted vectors are not compatible with NumPy or sklearn operations.\n",
        "\n",
        "**üîë Decryption Without Proper Context**\n",
        "\n",
        "The attacker creates a new TenSEAL context and attempts to decrypt the ciphertext.\n",
        "‚Üí Fails: Decryption requires the original private key tied to the encryption context."
      ],
      "metadata": {
        "id": "sJOgd4HdLbXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üö® Simulated Attacker Section\n",
        "print(\"\\nüõë Simulated Attacker Tries to Extract Information...\")\n",
        "\n",
        "try:\n",
        "    print(\"üîì Trying to read encrypted vector directly:\")\n",
        "    print(encrypted_vec)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Cannot read encrypted vector:\", e)\n",
        "\n",
        "try:\n",
        "    print(\"\\nüîç Trying cosine similarity on encrypted vector:\")\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    cosine_similarity([encrypted_vec], [embedding])  # Invalid: encrypted_vec is not a NumPy array\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Cosine similarity failed:\", e)\n",
        "\n",
        "try:\n",
        "    print(\"\\nüîë Trying to decrypt without context (attacker):\")\n",
        "    fake_context = ts.context(\n",
        "        ts.SCHEME_TYPE.CKKS,\n",
        "        poly_modulus_degree=8192,\n",
        "        coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "    )\n",
        "    fake_vec = ts.ckks_vector(fake_context, embedding.tolist())\n",
        "    _ = fake_vec.decrypt()  # Decryption fails due to missing keys\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Decryption failed (attacker has no private key):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrkCbOTSli6p",
        "outputId": "04cb53a2-f5ae-42ca-93ee-ea05fbb91d67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üõë Simulated Attacker Tries to Extract Information...\n",
            "üîì Trying to read encrypted vector directly:\n",
            "<tenseal.tensors.ckksvector.CKKSVector object at 0x7bf43b98ec90>\n",
            "\n",
            "üîç Trying cosine similarity on encrypted vector:\n",
            "‚ùå Cosine similarity failed: float() argument must be a string or a real number, not 'CKKSVector'\n",
            "\n",
            "üîë Trying to decrypt without context (attacker):\n",
            "‚ùå Decryption failed (attacker has no private key): no global scale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3CMZxELe-Uc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîê **Server-Side Encrypted Inference (Logistic + Homomorphic Sigmoid)**\n",
        "\n",
        "- **Flow**: Client encrypts `x` ‚Üí sends context (no SK) + `enc(x)` ‚Üí server computes `enc(z)=enc(x)¬∑w+b` and applies degree-5 sigmoid poly ‚Üí returns `enc(prob)` ‚Üí client decrypts.\n",
        "- **Sigmoid poly (deg-5)**: œÉ(x) ‚âà 0.5 + 0.2159198015¬∑x ‚àí 0.0082176259¬∑x¬≥ + 0.0001825597¬∑x‚Åµ. Odd powers preserve symmetry (œÉ(‚àíx)=1‚àíœÉ(x)); good accuracy near the decision boundary with modest HE depth.\n",
        "- **CKKS params**: N=16384; coeff_mod_bit_sizes `[60,40,40,40,40,60]`; global_scale `2^40`. Send public + relin + Galois keys only; secret key stays client-side.\n",
        "- **Security**: Server sees opaque ciphertexts and cannot decrypt or run plaintext ops; only the client can recover `p`.\n",
        "\n",
        "ü§è **Why decrypted `p` ‚â† plaintext `p` (slight drift)**\n",
        "- **CKKS is approximate**: fixed-point encoding + rescale/relinearize introduce tiny rounding noise that accumulates.\n",
        "- **Polynomial ‚â† true sigmoid**: degree-5 adds approximation error that grows with |z|.\n",
        "- **Eval schedule**: multiply/add order under HE differs from pure float64.\n",
        "\n",
        "*Reduce drift*: calibrate logits, use a larger scale or longer chain, or refit/raise the polynomial degree if depth allows.\n"
      ],
      "metadata": {
        "id": "HZrLh85f7XK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# üîê Encrypted logistic regression with server-side sigmoid (degree-5 poly)\n",
        "#\n",
        "#   Client constructs CKKS context at N=16384 with chain [60,40,40,40,40,60]\n",
        "#   and global_scale=2**40, then encrypts the embedding x.\n",
        "#\n",
        "#   Client sends context (public/relin/galois keys only; NO secret key) + enc(x).\n",
        "#\n",
        "#   Server computes enc(z) = enc(x)¬∑w + b, then approximates œÉ(z) with a 5th-degree\n",
        "#   odd polynomial using TenSEAL's CKKSVector.polyval (ascending coefficients).\n",
        "#\n",
        "#   Client decrypts the resulting probability p for the final decision.\n",
        "#\n",
        "# About the 5th-degree approximation:\n",
        "#   œÉ(x) ‚âà 0.5 + 0.2159198015*x ‚àí 0.0082176259*x^3 + 0.0001825597*x^5\n",
        "#   - Odd powers + 0.5 exploit œÉ(‚àíx) = 1 ‚àí œÉ(x) and œÉ(0)=0.5.\n",
        "#   - Degree-5 is a balance: good accuracy near the decision boundary with modest\n",
        "#     multiplicative depth. Higher degrees cost more chain/precision.\n",
        "#   - Empirically: on x‚àà[‚àí4,4], max error ~4e‚àí2; errors grow beyond |x|‚âà6, as all\n",
        "#     low-degree polynomials eventually overshoot the [0,1] range.\n",
        "#   - If your logits often exceed |6|, refit the polynomial for a wider band,\n",
        "#     raise degree (if chain allows), or use piecewise/Chebyshev fits.\n",
        "#\n",
        "# CKKS notes:\n",
        "#   - poly eval is done under encryption; TenSEAL manages rescale/relin as needed.\n",
        "#   - Using zeros for even-power coefficients preserves symmetry and saves multiplies.\n",
        "#   - The chosen chain length provides sufficient levels for dot + degree-5 eval.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "weights = np.asarray(model.coef_[0], dtype=np.float64)\n",
        "bias = float(model.intercept_[0])\n",
        "\n",
        "# --- Choose input and compute PLAINTEXT baseline ---\n",
        "test_text = \"I'm hesitating\"\n",
        "emb = encoder.encode([test_text], convert_to_numpy=True)[0].astype(np.float64)\n",
        "z_plain = float(np.dot(emb, weights) + bias)\n",
        "p_plain = 1.0 / (1.0 + np.exp(-z_plain))\n",
        "print(f\"[PLAINTEXT] z={z_plain:.6f}  p={p_plain:.4f}\")\n",
        "\n",
        "# --- Client: TenSEAL CKKS context (bumped to N=16384 for deeper polynomial) ---\n",
        "import tenseal as ts\n",
        "\n",
        "ctx = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "    # Plenty of depth room for degree-5 polynomial:\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 60],  # sum=280 (OK for N=16384)\n",
        ")\n",
        "ctx.global_scale = 2 ** 40\n",
        "ctx.generate_galois_keys()\n",
        "ctx.generate_relin_keys()\n",
        "\n",
        "# Encrypt embedding\n",
        "enc_vec = ts.ckks_vector(ctx, emb.tolist())\n",
        "\n",
        "# --- Server: encrypted z = w¬∑x + b, then sigmoid via degree-5 polynomial using polyval ---\n",
        "def server_encrypted_prob(context_bytes: bytes, enc_vec_bytes: bytes,\n",
        "                          weights: np.ndarray, bias: float) -> bytes:\n",
        "    sctx = ts.context_from(context_bytes)\n",
        "    enc_x = ts.ckks_vector_from(sctx, enc_vec_bytes)\n",
        "    enc_logit = enc_x.dot(weights) + float(bias)\n",
        "\n",
        "    # 5th-degree sigmoid approx (ascending powers for polyval):\n",
        "    # œÉ(x) ‚âà 0.5 + 0.2159198015 x ‚àí 0.0082176259 x^3 + 0.0001825597 x^5\n",
        "    coeffs = [0.5, 0.2159198015, 0.0, -0.0082176259, 0.0, 0.0001825597]\n",
        "    enc_prob = enc_logit.polyval(coeffs)  # TenSEAL handles rescale/relin internally\n",
        "    return enc_prob.serialize()\n",
        "\n",
        "# Send context WITHOUT secret key to server\n",
        "ctx_bytes_no_sk = ctx.serialize(\n",
        "    save_public_key=True, save_secret_key=False,\n",
        "    save_galois_keys=True, save_relin_keys=True\n",
        ")\n",
        "\n",
        "enc_prob_bytes = server_encrypted_prob(\n",
        "    ctx_bytes_no_sk,\n",
        "    enc_vec.serialize(),\n",
        "    weights,\n",
        "    bias,\n",
        ")\n",
        "\n",
        "# --- Client decrypts (use ORIGINAL ctx that holds SK) ---\n",
        "enc_prob = ts.ckks_vector_from(ctx, enc_prob_bytes)  # not a deserialized copy\n",
        "p_he = float(enc_prob.decrypt()[0])\n",
        "\n",
        "print(f\"[HE DECRYPT] p={p_he:.4f}\")\n",
        "print(\"‚úÖ Risk Detected\" if p_he > 0.5 else \"‚úÖ No Risk Detected\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZeTCZOu3lKx",
        "outputId": "54955421-b27e-4be9-ca5b-18356f63d417"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PLAINTEXT] z=-0.348502  p=0.4137\n",
            "[HE DECRYPT] p=0.4251\n",
            "‚úÖ No Risk Detected\n"
          ]
        }
      ]
    }
  ]
}
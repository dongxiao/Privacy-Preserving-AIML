{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ğŸ§  Privacy-Preserving Mental Health Risk Detection**\n",
        "\n",
        "This demo project demonstrates a lightweight privacy-preserving AI system for detecting early mental health risk from short text messages using encrypted inference. We simulate a realistic healthcare scenario where patient-generated data must remain confidentialâ€”yet still usable for AI-powered triage. By combining sentence embeddings, classical machine learning, and Fully Homomorphic Encryption (FHE), we enable secure inference on encrypted inputs without revealing sensitive text.\n",
        "\n",
        "**ğŸ” Key Features**\n",
        "\n",
        "**Federated Learning Scenario**: Model is trained locally; inference is performed securely on encrypted user inputsâ€”ideal for settings with distributed, sensitive healthcare data.\n",
        "\n",
        "\n",
        "**Privacy-Preserving AI**: Raw user data never leaves the client side unencryptedâ€”computation and risk scoring occur securely in ciphertext space.\n",
        "\n",
        "**Sentence Embeddings**: Uses all-MiniLM-L6-v2 to convert input text into dense semantic vectors.\n",
        "\n",
        "**Encrypted Inference with TenSEAL**: Applies the CKKS scheme to run logistic regression on encrypted embeddings.\n"
      ],
      "metadata": {
        "id": "XfrKkjpn-FLB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d3RH_mti6zR"
      },
      "source": [
        "!pip install sentence-transformers tenseal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ§® Introduction to CKKS and TenSEAL**\n",
        "\n",
        "To enable privacy-preserving inference over sensitive clinical text, this project leverages the CKKS (Cheon-Kim-Kim-Song) scheme for approximate homomorphic encryption. Unlike traditional encryption, CKKS supports arithmetic directly on encrypted real numbers, making it ideal for machine learning workflows involving floating-point operations like dot products and linear models.\n",
        "\n",
        "We use [TenSEAL](https://github.com/OpenMined/TenSEAL) â€” a Python library built on top of Microsoft SEAL â€” to:\n",
        "\n",
        "\n",
        "\n",
        "*   Encrypt high-dimensional sentence embeddings (e.g., from MiniLM)\n",
        "*   Perform encrypted linear inference (e.g., logistic regression)\n",
        "*   Decrypt only the final result, preserving end-to-end confidentiality\n",
        "*   By operating entirely on ciphertexts, TenSEAL allows computations to be outsourced to untrusted environments (e.g., cloud or remote nodes) without revealing inputs, model parameters, or intermediate results.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7kTzMoeVNh_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1. Simulate 400 labeled text messages\n",
        "mental_health_texts = [\n",
        "    \"I feel hopeless and tired all the time.\",\n",
        "    \"Lately, I can't concentrate and everything feels overwhelming.\",\n",
        "    \"I barely talk to anyone and feel isolated.\",\n",
        "    \"School is stressing me out beyond what I can handle.\",\n",
        "    \"I have no energy to do anything, even things I used to enjoy.\",\n",
        "    \"I feel anxious constantly, even when nothing is wrong.\",\n",
        "    \"I'm not sleeping well and my appetite is gone.\",\n",
        "    \"Everything feels meaningless and I just want to be left alone.\",\n",
        "    \"I cry randomly and can't explain why.\",\n",
        "    \"Even getting out of bed feels like a chore.\"\n",
        "] * 20  # 200 samples\n",
        "\n",
        "no_problem_texts = [\n",
        "    \"Iâ€™ve been sleeping well and enjoying my time with friends.\",\n",
        "    \"I feel confident and motivated about my goals.\",\n",
        "    \"Iâ€™ve been going for daily walks and eating healthy.\",\n",
        "    \"Things at school are busy but manageable.\",\n",
        "    \"I enjoy socializing and staying active.\",\n",
        "    \"Life has been stable and Iâ€™m feeling grateful.\",\n",
        "    \"Iâ€™ve been productive and focused lately.\",\n",
        "    \"My energy levels are good and I feel optimistic.\",\n",
        "    \"Iâ€™ve been taking care of myself and feeling balanced.\",\n",
        "    \"Everything is going smoothly and Iâ€™m content.\"\n",
        "] * 20  # 200 samples\n",
        "\n",
        "texts = mental_health_texts + no_problem_texts\n",
        "labels = [1]*200 + [0]*200\n",
        "\n",
        "df = pd.DataFrame({'text': texts, 'mental_health_problem': labels})\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 2. Encode messages into embeddings\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_embeddings = encoder.encode(df['text'].tolist())\n",
        "y = df['mental_health_problem'].values\n",
        "\n",
        "# 3. Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHJnC7UEAQLg",
        "outputId": "ca7c1311-f450-4f1d-b5f8-4702b9b685b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”“ Plaintext Inference Version**\n",
        "\n",
        "This simplified version demonstrates the same mental health risk detection pipeline without encryption, serving as a baseline for comparison.\n",
        "\n",
        "*   Text messages are embedded using a pretrained MiniLM model.\n",
        "*   A logistic regression classifier predicts mental health risk based on those embeddings.\n",
        "*   Inference is performed directly on plaintext vectors using a standard dot product.\n",
        "*   Useful for validating model performance before deploying privacy-preserving encrypted inference.\n"
      ],
      "metadata": {
        "id": "1pfpOBwHBSRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Predict on new input (plaintext inference)\n",
        "test_text = \"I feel hopeless and tired all the time.\"\n",
        "embedding = encoder.encode([test_text])[0]\n",
        "score = np.dot(model.coef_[0], embedding) + model.intercept_[0]\n",
        "probability = 1 / (1 + np.exp(-score))\n",
        "\n",
        "print(f\"\\nPrediction probability for:\\n\\\"{test_text}\\\"\\nâ†’ {probability:.4f}\")\n",
        "print(\"âœ… Risk Detected\" if probability > 0.5 else \"âœ… No Risk Detected\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb3De6iVCKOO",
        "outputId": "d0a551c8-a43d-4e4e-c754-3088f973dd74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction probability for:\n",
            "\"I feel hopeless and tired all the time.\"\n",
            "â†’ 0.9036\n",
            "âœ… Risk Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ” Why Encryption Matters in Clinical AI: Protecting Against Embedding Leakage**\n",
        "\n",
        "\n",
        "\n",
        "*   ğŸ”“ Note: In clinical environments, using plaintext or even unencrypted embeddings is generally not permitted, as embeddingsâ€”though not directly human-readableâ€”can still be vulnerable to inversion or re-identification attacks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J3juGu1MIGMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load encoder and corpus of possible texts\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "corpus_sentences = [\n",
        "    \"I feel tired and sad all the time.\",\n",
        "    \"I'm excited about my new project.\",\n",
        "    \"Everything feels meaningless.\",\n",
        "    \"I can't concentrate on anything lately.\",\n",
        "    \"Iâ€™ve been sleeping well and eating healthy.\",\n",
        "    \"Life is overwhelming and I want to cry.\",\n",
        "    \"My motivation is gone and I feel hopeless.\"\n",
        "]\n",
        "\n",
        "# 2. Encode known corpus of candidate sentences\n",
        "corpus_embeddings = encoder.encode(corpus_sentences)\n",
        "\n",
        "# 3. Simulate intercepted embedding (e.g., from a client query)\n",
        "simulated_embedding = embedding = encoder.encode([test_text])[0]  # This is what gets intercepted\n",
        "\n",
        "# 4. Attacker attempts reconstruction via cosine similarity\n",
        "similarities = cosine_similarity([simulated_embedding], corpus_embeddings)\n",
        "closest_idx = np.argmax(similarities)\n",
        "\n",
        "# 5. Display result\n",
        "print(f\"â— Intercepted embedding likely corresponds to:\")\n",
        "print(f\"ğŸ” Closest match: \\\"{corpus_sentences[closest_idx]}\\\"\")\n",
        "print(f\"ğŸ“ˆ Similarity score: {similarities[0][closest_idx]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT5fPcJ8Hkbl",
        "outputId": "54eb104e-fabd-438a-9907-6fb6ece6ea62"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â— Intercepted embedding likely corresponds to:\n",
            "ğŸ” Closest match: \"I feel tired and sad all the time.\"\n",
            "ğŸ“ˆ Similarity score: 0.7972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ” Encrypted Inference with CKKS (TenSEAL)**\n",
        "\n",
        "This version demonstrates inference over encrypted input using the CKKS homomorphic encryption scheme via the TenSEAL library.\n",
        "\n",
        "\n",
        "*   This setup mimics a privacy-preserving inference service where sensitive user input remains encrypted throughout the prediction processâ€”ideal for federated healthcare settings or scenarios involving untrusted compute infrastructure.\n",
        "*   The input embedding (from MiniLM) is encrypted using CKKS before being sent to the model.\n",
        "*   The logistic regression model performs a dot product and adds bias entirely in ciphertext space.\n",
        "*   The encrypted result is decrypted only after computation, and the sigmoid function is applied client-side to produce a probability score.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0OljuveKColy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Setup TenSEAL encryption context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        ")\n",
        "context.global_scale = 2 ** 40\n",
        "context.generate_galois_keys()\n",
        "\n",
        "# 6. Encrypted inference\n",
        "test_text = \"I feel hopeless and tired all the time.\"\n",
        "#test_text = \"I am good.\"\n",
        "embedding = encoder.encode([test_text])[0]\n",
        "\n",
        "encrypted_vec = ts.ckks_vector(context, embedding.tolist())\n",
        "\n",
        "weights = model.coef_[0]\n",
        "bias = model.intercept_[0]\n",
        "\n",
        "# Compute encrypted dot product + bias\n",
        "encrypted_result = encrypted_vec.dot(weights) + bias\n",
        "\n",
        "# Decrypt and apply sigmoid\n",
        "score = encrypted_result.decrypt()[0]\n",
        "probability = 1 / (1 + np.exp(-score))\n",
        "\n",
        "print(f\"\\nEncrypted prediction probability for:\\n\\\"{test_text}\\\"\\nâ†’ {probability:.4f}\")\n",
        "print(\"âœ… Risk Detected\" if probability > 0.5 else \"âœ… No Risk Detected\")"
      ],
      "metadata": {
        "id": "-MJLokpVYrh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5889293a-26fb-47ae-fb3a-9a2294b37161"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encrypted prediction probability for:\n",
            "\"I feel hopeless and tired all the time.\"\n",
            "â†’ 0.9036\n",
            "âœ… Risk Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ›¡ï¸ Simulated Attacker Scenario: Why Homomorphic Encryption Prevents Data Leakage**\n",
        "\n",
        "This section demonstrates how a malicious actor â€” even if they intercept the encrypted embedding or encrypted inference result â€” cannot extract any meaningful information.\n",
        "\n",
        "Three common attack attempts are shown:\n",
        "\n",
        "**ğŸ”“ Direct Inspection of Encrypted Vector**\n",
        "\n",
        "The attacker tries to read or print the contents of the encrypted vector.\n",
        "â†’ Fails: CKKS ciphertexts are opaque; raw values are hidden.\n",
        "\n",
        "**ğŸ” Cosine Similarity Matching**\n",
        "\n",
        "The attacker tries to compare the encrypted vector with known plaintext embeddings (e.g. via cosine similarity) to infer meaning.\n",
        "â†’ Fails: Encrypted vectors are not compatible with NumPy or sklearn operations.\n",
        "\n",
        "**ğŸ”‘ Decryption Without Proper Context**\n",
        "\n",
        "The attacker creates a new TenSEAL context and attempts to decrypt the ciphertext.\n",
        "â†’ Fails: Decryption requires the original private key tied to the encryption context."
      ],
      "metadata": {
        "id": "sJOgd4HdLbXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš¨ Simulated Attacker Section\n",
        "print(\"\\nğŸ›‘ Simulated Attacker Tries to Extract Information...\")\n",
        "\n",
        "try:\n",
        "    print(\"ğŸ”“ Trying to read encrypted vector directly:\")\n",
        "    print(encrypted_vec)\n",
        "except Exception as e:\n",
        "    print(\"âŒ Cannot read encrypted vector:\", e)\n",
        "\n",
        "try:\n",
        "    print(\"\\nğŸ” Trying cosine similarity on encrypted vector:\")\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    cosine_similarity([encrypted_vec], [embedding])  # Invalid: encrypted_vec is not a NumPy array\n",
        "except Exception as e:\n",
        "    print(\"âŒ Cosine similarity failed:\", e)\n",
        "\n",
        "try:\n",
        "    print(\"\\nğŸ”‘ Trying to decrypt without context (attacker):\")\n",
        "    fake_context = ts.context(\n",
        "        ts.SCHEME_TYPE.CKKS,\n",
        "        poly_modulus_degree=8192,\n",
        "        coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
        "    )\n",
        "    fake_vec = ts.ckks_vector(fake_context, embedding.tolist())\n",
        "    _ = fake_vec.decrypt()  # Decryption fails due to missing keys\n",
        "except Exception as e:\n",
        "    print(\"âŒ Decryption failed (attacker has no private key):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrkCbOTSli6p",
        "outputId": "56ac4b7f-8ce5-40c6-eb09-9bf59f2240bf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ›‘ Simulated Attacker Tries to Extract Information...\n",
            "ğŸ”“ Trying to read encrypted vector directly:\n",
            "<tenseal.tensors.ckksvector.CKKSVector object at 0x7a61bf60aed0>\n",
            "\n",
            "ğŸ” Trying cosine similarity on encrypted vector:\n",
            "âŒ Cosine similarity failed: float() argument must be a string or a real number, not 'CKKSVector'\n",
            "\n",
            "ğŸ”‘ Trying to decrypt without context (attacker):\n",
            "âŒ Decryption failed (attacker has no private key): no global scale\n"
          ]
        }
      ]
    }
  ]
}